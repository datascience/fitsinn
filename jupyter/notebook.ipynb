{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_median1(values, weights):\n",
    "    sorted_indices = np.argsort(values)\n",
    "    sorted_values = sorted(values)\n",
    "    sorted_weights = sorted(weights)\n",
    "\n",
    "    cumulative_weights = np.cumsum(sorted_weights)\n",
    "    total_weight = np.sum(sorted_weights)\n",
    "\n",
    "    # Find the median index\n",
    "    median_index = np.searchsorted(cumulative_weights, total_weight / 2.0)\n",
    "\n",
    "    return sorted_values[median_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def weighted_median(df, val, weight):\n",
    "#    df_sorted = df.sort_values(val)\n",
    "#    cumsum = df_sorted[weight].cumsum()\n",
    "#    cutoff = df_sorted[weight].sum() / 2.\n",
    "#    return df_sorted[cumsum >= cutoff][val].iloc[0]\n",
    "\n",
    "#weighted_median(df, 'impwealth', 'indweight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/weather_data_set.txt', sep=\"\\t\",  header=None)\n",
    "groundtruth = pd.read_csv('data/weather_ground_truth.txt', sep=\"\\t\")\n",
    "iti = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main CRH Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sort_values(by=[0], inplace=True)\n",
    "\n",
    "# Calculate statistics about the data\n",
    "nof = len(dataset)\n",
    "# Get the entry list\n",
    "list_entry = dataset[0].unique()\n",
    "# Get the source list\n",
    "list_source = dataset[2].unique()\n",
    "# Number of sources\n",
    "nos = len(list_source)\n",
    "# Number of entries\n",
    "noe = len(list_entry)\n",
    "\n",
    "# Modify entry_ia so that the following works\n",
    "entry_ia = np.append(np.arange(0, noe), nof)\n",
    "\n",
    "# Initialization\n",
    "ini_truth = []\n",
    "weight = np.ones(nos) / nos\n",
    "\n",
    "weight_vector = weight[dataset[2].values-1]\n",
    "weight_matrix = pd.DataFrame(weight_vector, columns=['weight'],index = dataset.index)\n",
    "# Calculate initial truth entry by entry\n",
    "\n",
    "stand_error=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight\n",
       "333  0.111111\n",
       "153  0.111111"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix.loc[ [333, 153]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  333,   153,   334,   154,   335,   155,   336,   675,   855,   156,\n",
       "       ...\n",
       "       15650, 15657, 15658, 15659, 15666, 15667, 15668, 15675, 15676, 15677],\n",
       "      dtype='int64', length=16038)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry_id in list_entry:\n",
    "    val = dataset[dataset[0] == entry_id].values[0,1]\n",
    " \n",
    "    if not val.lstrip('-+').isdigit():  # Categorical data\n",
    "        same_entry = dataset[dataset[0]==entry_id]\n",
    "        tempvalue = same_entry[1].values\n",
    "        # Get unique value list on the same entry\n",
    "        temp_list = same_entry[1].unique()\n",
    "        wv = []\n",
    "\n",
    "        # Calculate the weighted occurrence for this entry\n",
    "        for k in range(len(temp_list)):\n",
    "            wv.append(np.sum(((tempvalue == temp_list[k]) * weight_matrix.loc[same_entry.index].values)))\n",
    "\n",
    "        # Get the voting result\n",
    "        I = np.argmax(wv)\n",
    "        ini_truth.append([entry_id, temp_list[I]])\n",
    "\n",
    "    else:  # Numerical data\n",
    "        \n",
    "        same_entry = dataset[dataset[0]==entry_id]\n",
    "        \n",
    "        tempvalue = same_entry[1].values\n",
    "        tempvalue_int = [int(x) for x in tempvalue]\n",
    "        median = np.median(tempvalue_int)\n",
    "        \n",
    "        # Calculate median for this entry\n",
    "        ini_truth.append([entry_id, median])\n",
    "        stand_error.append([entry_id,np.std(tempvalue_int) ])\n",
    "index_truth = [] #ini_truth.copy()\n",
    "truth_matrix = pd.DataFrame(ini_truth, columns=['entry_id', 'truth'])\n",
    "std_matrix = pd.DataFrame(stand_error, columns=['entry_id', 'error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize other parameters\n",
    "cat_count = np.zeros(nos)  # Count of categorical data for each source\n",
    "con_count = np.zeros(nos)  # Count of continuous data for each source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8408\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[142], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m         index_truth\u001b[38;5;241m.\u001b[39mappend([entry_id, wm])\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(index_truth))\n\u001b[0;32m---> 57\u001b[0m truth_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mindex_truth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m[dataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "for i in range(iti):\n",
    "    score1 = np.zeros(nos)\n",
    "    score2 = np.zeros(nos)\n",
    "\n",
    "    # Update weight\n",
    "    \n",
    "    for j in range(len(dataset)):\n",
    "        val = dataset.loc[j].values[1]\n",
    "        entry_id = dataset.loc[j].values[0]\n",
    "        source_id = dataset.loc[j].values[2]\n",
    "        true_val=truth_matrix[truth_matrix['entry_id'] == entry_id].values[0,1]\n",
    "        if not val.lstrip('-+').isdigit():\n",
    "            true_val=truth_matrix[truth_matrix['entry_id'] == entry_id].values[0,1]\n",
    "            score1[source_id-1] += int(true_val != val)  #we count non-matching TypeError: weighted_median() missing 1 required positional argument: 'weight'values\n",
    "            #if i == 2:\n",
    "            cat_count[source_id-1] += 1\n",
    "        else:  # Numerical data\n",
    "            error=std_matrix[std_matrix['entry_id'] == entry_id].values[0,1]\n",
    "            if (error != 0 ):\n",
    "                score2[source_id-1] += np.abs( int(val) - int(true_val)) / error\n",
    "\n",
    "            #if i == 2:\n",
    "            con_count[source_id-1] += 1\n",
    "    score1 /= cat_count\n",
    "    score2 /= con_count\n",
    "    score1 /= sum(score1)\n",
    "    score2 /= sum(score2)\n",
    "\n",
    "    score = score1 + score2\n",
    "    norm_score = np.max(score)\n",
    "    w = score / norm_score\n",
    "    weight = -np.log(w) + 0.00001\n",
    "\n",
    "    weight_vector = weight[dataset[2].values-1]\n",
    "    weight_matrix = pd.DataFrame(weight_vector, columns=['weight'],index = dataset.index)\n",
    "    for entry_id in list_entry:\n",
    "        val = dataset[dataset[0] == entry_id].values[0,1]\n",
    "        if not val.lstrip('-+').isdigit():  # Categorical data\n",
    "            same_entry = dataset[dataset[0]==entry_id]\n",
    "            tempvalue = same_entry[1].values\n",
    "            temp_list = same_entry[1].unique()\n",
    "            wv = []\n",
    "            for k in range(len(temp_list)):\n",
    "                wv.append(np.sum(((tempvalue == temp_list[k]) * weight_matrix.loc[same_entry.index].values)))\n",
    "            I = np.argmax(wv)\n",
    "            index_truth.append([entry_id, temp_list[I]])\n",
    "        else:  # Numerical data\n",
    "            same_entry = dataset[dataset[0]==entry_id]\n",
    "            tempvalue = same_entry[1].values\n",
    "            tempvalue_int = [int(x) for x in tempvalue]\n",
    "            \n",
    "            tempweight=weight_matrix.loc[same_entry.index].values\n",
    "            wm = weighted_median1(tempvalue_int, tempweight)\n",
    "            index_truth.append([entry_id, wm])\n",
    "\n",
    "    print(len(index_truth))\n",
    "    truth_matrix = index_truth.loc[dataset[0].values].reset_index(drop=True)[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "       \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iti):\n",
    "        score1 = np.zeros(nos)\n",
    "        score2 = np.zeros(nos)\n",
    "\n",
    "        # Update weight\n",
    "        \n",
    "        for j in range(len(dataset)):\n",
    "            print(dataset.loc[j])\n",
    "            val = dataset.loc[j].values[1]\n",
    "            if not val.isdigit():\n",
    "           # if pd.api.types.is_string_dtype(dataset.at[j, 1]):  # Categorical data\n",
    "                score1[dataset.at[j, 2]] += int(truth_matrix[j] != dataset.at[j, 1])\n",
    "\n",
    "                if i == 2:\n",
    "                    cat_count[dataset.at[j, 2]] += 1\n",
    "            else:  # Numerical data\n",
    "                score2[dataset.at[j, 2]] += np.abs((pd.to_numeric(dataset.at[j, 1]) - truth_matrix[j]) / std_matrix[j])\n",
    "\n",
    "                if i == 2:\n",
    "                    con_count[dataset.at[j, 2]] += 1\n",
    "\n",
    "        score1 /= cat_count\n",
    "        score2 /= con_count\n",
    "        score1 /= np.sum(score1)\n",
    "        score2 /= np.sum(score2)\n",
    "\n",
    "        # Sum up the distance for categorical and continuous data\n",
    "        score = score1 + score2\n",
    "\n",
    "        # Calculate weight for sources\n",
    "        norm_score = np.max(score)\n",
    "        w = score / norm_score\n",
    "        weight = -np.log(w) + 0.00001\n",
    "        weight_matrix = weight[dataset[2].values]\n",
    "\n",
    "\n",
    "    \n",
    "        # Update truth\n",
    "        for j in range(noe):\n",
    "            if pd.api.types.is_string_dtype(dataset.at[entry_ia[j], 1]):  # Categorical data\n",
    "                tempvalue = dataset.loc[entry_ia[j]:entry_ia[j + 1] - 1, 1]\n",
    "                temp_list = tempvalue.unique()\n",
    "                length_list = len(temp_list)\n",
    "\n",
    "                wv = []\n",
    "                for k in range(length_list):\n",
    "                    wv.append(np.sum((tempvalue == temp_list[k]) * weight_matrix[entry_ia[j]:entry_ia[j + 1]]))\n",
    "\n",
    "                I = np.argmax(wv)\n",
    "                index_truth.at[j + 1, 2] = temp_list[I]\n",
    "\n",
    "            else:  # Numerical data\n",
    "                tempvalue = pd.to_numeric(dataset.loc[entry_ia[j]:entry_ia[j + 1] - 1, 1])\n",
    "                tempweight = weight_matrix[entry_ia[j]:entry_ia[j + 1]]\n",
    "\n",
    "                # Update truth by weighted median\n",
    "                index_truth.at[j + 1, 2] = weighted_median(tempvalue.values, tempweight)\n",
    "\n",
    "        truth_matrix = index_truth.loc[dataset[0].values].reset_index(drop=True)[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof = len(dataset)\n",
    "list_entry, entry_ia, entry_ic = np.unique(dataset[\"entry_id\"], return_index=True, return_inverse=True)\n",
    "list_source, _, source_ic = np.unique(dataset[\"source_index\"], return_index=True, return_inverse=True)\n",
    "nos = len(list_source)\n",
    "noe = len(entry_ia)\n",
    "entry_ia = np.append(entry_ia, nof + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "ini_truth = []\n",
    "weight = np.ones(nos) / nos\n",
    "weight_matrix = weight[source_ic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(noe):\n",
    "    ini_truth.append([dataset.iloc[entry_ia[i], 0], None])\n",
    "    if dataset.iloc[entry_ia[i], 1].replace('.', '', 1).isdigit():  # numerical data\n",
    "        tempvalue = dataset.iloc[entry_ia[i]: entry_ia[i + 1] - 1, 1].astype(float)\n",
    "        ini_truth[i][1] = np.median(tempvalue)\n",
    "    else:  # categorical data\n",
    "        tempvalue = dataset.iloc[entry_ia[i]: entry_ia[i + 1] - 1, 1]\n",
    "        temp_list, counts = np.unique(tempvalue, return_counts=True)\n",
    "        wv = np.zeros(len(temp_list))\n",
    "        for k in range(len(temp_list)):\n",
    "            wv[k] = sum((tempvalue == temp_list[k]) * weight_matrix[entry_ia[i]: entry_ia[i + 1] - 1])\n",
    "        ini_truth[i][1] = temp_list[np.argmax(wv)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(dataset, columns=[\"entry_id\", \"observation\", \"source_index\"])\n",
    "dataset = dataset.sort_values(by=\"entry_id\")\n",
    "\n",
    "# Calculate statistics about the data\n",
    "nof = len(dataset)\n",
    "list_entry, entry_ia, entry_ic = np.unique(dataset[\"entry_id\"], return_index=True, return_inverse=True)\n",
    "list_source, _, source_ic = np.unique(dataset[\"source_index\"], return_index=True, return_inverse=True)\n",
    "nos = len(list_source)\n",
    "noe = len(entry_ia)\n",
    "entry_ia = np.append(entry_ia, nof + 1)\n",
    "\n",
    "# Initialization\n",
    "ini_truth = []\n",
    "weight = np.ones(nos) / nos\n",
    "weight_matrix = weight[source_ic]\n",
    "\n",
    "for i in range(noe):\n",
    "    ini_truth.append([dataset.iloc[entry_ia[i], 0], None])\n",
    "    if dataset.iloc[entry_ia[i], 1].replace('.', '', 1).isdigit():  # numerical data\n",
    "        tempvalue = dataset.iloc[entry_ia[i]: entry_ia[i + 1] - 1, 1].astype(float)\n",
    "        ini_truth[i][1] = np.median(tempvalue)\n",
    "    else:  # categorical data\n",
    "        tempvalue = dataset.iloc[entry_ia[i]: entry_ia[i + 1] - 1, 1]\n",
    "        temp_list, counts = np.unique(tempvalue, return_counts=True)\n",
    "        wv = np.zeros(len(temp_list))\n",
    "        for k in range(len(temp_list)):\n",
    "            wv[k] = sum((tempvalue == temp_list[k]) * weight_matrix[entry_ia[i]: entry_ia[i + 1] - 1])\n",
    "        ini_truth[i][1] = temp_list[np.argmax(wv)]\n",
    "\n",
    "index_truth = ini_truth.copy()\n",
    "truth_matrix = [ini_truth[i][1] for i in entry_ic]\n",
    "std_matrix = np.zeros(len(entry_ic))\n",
    "\n",
    "cat_count = np.zeros(nos)\n",
    "con_count = np.zeros(nos)\n",
    "\n",
    "i = 1\n",
    "while i <= iti:\n",
    "    i += 1\n",
    "    score1 = np.zeros(nos)\n",
    "    score2 = np.zeros(nos)\n",
    "\n",
    "    for j in range(nof):\n",
    "        if dataset.iloc[j, 1].replace('.', '', 1).isdigit():\n",
    "            score2[dataset.iloc[j, 2]] += abs((float(dataset.iloc[j, 1]) - truth_matrix[j]) / std_matrix[j])\n",
    "            if i == 2:\n",
    "                con_count[dataset.iloc[j, 2]] += 1\n",
    "        else:\n",
    "            score1[dataset.iloc[j, 2]] += (truth_matrix[j] != dataset.iloc[j, 1])\n",
    "            if i == 2:\n",
    "                cat_count[dataset.iloc[j, 2]] += 1\n",
    "\n",
    "    score1 /= cat_count\n",
    "    score2 /= con_count\n",
    "    score1 /= np.sum(score1)\n",
    "    score2 /= np.sum(score2)\n",
    "\n",
    "    score = score1 + score2\n",
    "    norm_score = max(score)\n",
    "    w = score / norm_score\n",
    "    weight = -np.log(w) + 0.00001\n",
    "    weight_matrix = weight[source_ic]\n",
    "\n",
    "    for j in range(noe):\n",
    "        if dataset.iloc[entry_ia[j], 1].replace('.', '', 1).isdigit():\n",
    "            tempvalue = dataset.iloc[entry_ia[j]: entry_ia[j + 1] - 1, 1].astype(float)\n",
    "            tempweight = weight_matrix[entry_ia[j]: entry_ia[j + 1] - 1]\n",
    "            index_truth[j][1] = weightedMedian(tempvalue, tempweight)\n",
    "        else:\n",
    "            tempvalue = dataset.iloc[entry_ia[j]: entry_ia[j + 1] - 1, 1]\n",
    "            temp_list, counts = np.unique(tempvalue, return_counts=True)\n",
    "            wv = np.zeros(len(temp_list))\n",
    "            for k in range(len(temp_list)):\n",
    "                wv[k] = sum((tempvalue == temp_list[k]) * weight_matrix[entry_ia[j]: entry_ia[j + 1] - 1])\n",
    "            index_truth[j][1] = temp_list[np.argmax(wv)]\n",
    "\n",
    "    truth_matrix = [index_truth[i][1] for i in entry_ic]\n",
    "\n",
    "weight = np.column_stack((list_source, weight))\n",
    "return index_truth, weight, ini_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "545e7J28--Zj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statistics import median\n",
    "import csv\n",
    "# Convert 'importfile_data' and 'importfile_gt' functions as needed to read the data files.\n",
    "\n",
    "def evaluate_weather(crh_truth, ground_truth):\n",
    "    # Implement the evaluation of the CRH results against the ground truth in this function.\n",
    "    # Return the error rate and MNAD (Mean Normalized Absolute Deviation) as required.\n",
    "  pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfCZ8oErbtXz"
   },
   "outputs": [],
   "source": [
    "\n",
    "def weighted_median(D, W):\n",
    "    if D.shape != W.shape:\n",
    "        raise ValueError('The dimensions of the input-matrices must match.')\n",
    "\n",
    "    # normalize the weights, such that: sum ( w_ij ) = 1\n",
    "    WSum = np.sum(W)\n",
    "    W = W / WSum\n",
    "\n",
    "    # transformation of the input-matrices to vectors\n",
    "    d = D.flatten()\n",
    "    w = W.flatten()\n",
    "\n",
    "    # sort the vectors\n",
    "    sorted_indices = np.argsort(d)\n",
    "    d_sorted = d[sorted_indices]\n",
    "    w_sorted = w[sorted_indices]\n",
    "\n",
    "    # Calculate cumulative sums of the weights\n",
    "    sumVec = np.cumsum(w_sorted)\n",
    "\n",
    "    wMed = None\n",
    "    j = 0\n",
    "\n",
    "    while wMed is None:\n",
    "        if sumVec[j] >= 0.5:\n",
    "            wMed = d_sorted[j]\n",
    "        j += 1\n",
    "\n",
    "    if (np.sum(w_sorted[:j - 1]) > 0.5) and (np.sum(w_sorted[j:]) > 0.5):\n",
    "        raise ValueError('The weighted median could not be calculated.')\n",
    "\n",
    "    return wMed\n",
    "\n",
    "def CRH_weather(dataset, iti):\n",
    "    if not np.all(np.diff(dataset[:, 0]) >= 0):\n",
    "        dataset = dataset[dataset[:, 0].argsort()]\n",
    "\n",
    "    nof = np.array(dataset).shape[0]\n",
    "    list_entry, entry_ia, entry_ic = np.unique(dataset[:, 0], return_index=True, return_inverse=True)\n",
    "    list_source, _, source_ic = np.unique(dataset[:, 2], return_index=True, return_inverse=True)\n",
    "    nos = len(list_source)\n",
    "    noe = len(entry_ia)\n",
    "\n",
    "    entry_ia = np.append(entry_ia, nof + 1)\n",
    "\n",
    "    ini_truth = []\n",
    "    weight = np.ones(nos) / nos\n",
    "    weight_matrix = weight[source_ic]\n",
    "    standerror = np.zeros(nof)\n",
    "\n",
    "    for i in range(noe):\n",
    "        ini_truth.append([dataset[entry_ia[i], 0], None])\n",
    "\n",
    "        if not dataset[entry_ia[i], 1].replace('.', '', 1).isdigit():\n",
    "            tempvalue = dataset[entry_ia[i]: entry_ia[i + 1], 1]\n",
    "            temp_list, counts = np.unique(tempvalue, return_counts=True)\n",
    "            wv = [np.sum((tempvalue == val) * weight_matrix[entry_ia[i]: entry_ia[i + 1]]) for val in temp_list]\n",
    "            I = np.argmax(wv)\n",
    "            ini_truth[i][1] = temp_list[I]\n",
    "        else:\n",
    "            tempvalue = dataset[entry_ia[i]: entry_ia[i + 1], 1].astype(float)\n",
    "            ini_truth[i][1] = median(tempvalue)\n",
    "            standerror[i] = np.std(tempvalue) + 0.1\n",
    "\n",
    "    index_truth = ini_truth\n",
    "    truth_matrix = np.array([x[1] for x in ini_truth])[entry_ic]\n",
    "    std_matrix = standerror[entry_ic]\n",
    "\n",
    "    cat_count = np.zeros(nos)\n",
    "    con_count = np.zeros(nos)\n",
    "\n",
    "    i = 1\n",
    "    while i <= iti:\n",
    "        i += 1\n",
    "        score1 = np.zeros(nos)\n",
    "        score2 = np.zeros(nos)\n",
    "\n",
    "        for j in range(nof):\n",
    "            if not dataset[j, 1].replace('.', '', 1).isdigit():\n",
    "                score1[int(dataset[j, 2])] += truth_matrix[j] != dataset[j, 1]\n",
    "                if i == 2:\n",
    "                    cat_count[int(dataset[j, 2])] += 1\n",
    "            else:\n",
    "                score2[int(dataset[j, 2])] += abs((float(dataset[j, 1]) - truth_matrix[j]) / std_matrix[j])\n",
    "                if i == 2:\n",
    "                    con_count[int(dataset[j, 2])] += 1\n",
    "\n",
    "        score1 /= cat_count\n",
    "        score2 /= con_count\n",
    "        score1 /= np.sum(score1)\n",
    "        score2 /= np.sum(score2)\n",
    "\n",
    "        score = score1 + score2\n",
    "        norm_score = np.max(score)\n",
    "        w = score / norm_score\n",
    "        weight = -np.log(w) + 0.00001\n",
    "        weight_matrix = weight[source_ic]\n",
    "\n",
    "        for j in range(noe):\n",
    "            if not dataset[entry_ia[j], 1].replace('.', '', 1).isdigit():\n",
    "                tempvalue = dataset[entry_ia[j]: entry_ia[j + 1], 1]\n",
    "                temp_list, _ = np.unique(tempvalue, return_counts=True)\n",
    "                wv = [np.sum((tempvalue == val) * weight_matrix[entry_ia[j]: entry_ia[j + 1]]) for val in temp_list]\n",
    "                I = np.argmax(wv)\n",
    "                index_truth[j][1] = temp_list[I]\n",
    "            else:\n",
    "                tempvalue = dataset[entry_ia[j]: entry_ia[j + 1], 1].astype(float)\n",
    "                tempweight = weight_matrix[entry_ia[j]: entry_ia[j + 1]]\n",
    "                index_truth[j][1] = weighted_median(tempvalue, tempweight)\n",
    "\n",
    "        truth_matrix = np.array([x[1] for x in index_truth])[entry_ic]\n",
    "\n",
    "    weight = np.column_stack((list_source, weight))\n",
    "    return index_truth, weight, ini_truth\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'dataset' is a 2D NumPy array.\n",
    "# iti = 10  # Maximum number of iterations\n",
    "# index_truth, weight, ini_truth = CRH_weather(dataset, iti)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "gr1CKwI8bnHO",
    "outputId": "06ee8a67-6f14-4e5f-88df-f0824b7af390"
   },
   "outputs": [],
   "source": [
    "# Import data and ground truth\n",
    "weather =  importfile_data('data/weather_data_set.txt')\n",
    "ground_truth = importfile_gt('data/weather_ground_truth.txt')\n",
    "\n",
    "#weather[:, 0]=weather[:, 0].astype(float).astype(int)\n",
    "# Set minimum and maximum iterations\n",
    "min_iti = 3\n",
    "max_iti = 3\n",
    "result_CRH = np.zeros((max_iti - min_iti + 1, 3))\n",
    "\n",
    "i = 0\n",
    "# Start CRH iteration\n",
    "for iti in range(min_iti, max_iti + 1):\n",
    "  i += 1\n",
    "  print(f\"{i}th run: iteration = {iti} ...\")\n",
    "\n",
    "  # Run CRH\n",
    "  crh_truth, crh_weight, voting_median_truth = CRH_weather(weather, iti)\n",
    "\n",
    "  # Evaluate CRH result for current iteration\n",
    "  error_rate, MNAD = evaluate_weather(crh_truth, ground_truth)\n",
    "  result_CRH[i - 1, :] = [iti, error_rate, MNAD]\n",
    "\n",
    "# Save CRH result\n",
    "print(\"saving CRH result...\")\n",
    "np.savetxt('result_CRH.txt', result_CRH, fmt='%1.4f', delimiter='\\t')\n",
    "\n",
    "# Voting/Median method\n",
    "# If you want to evaluate the results from the Voting/Median method, you can\n",
    "# uncomment the following code and implement the necessary evaluation functions.\n",
    "\n",
    "# Evaluate Voting/Median result for current iteration\n",
    "# error_rate, MNAD = evaluate_truthmine(crh_truth, ground_truth)\n",
    "# result_vm = [error_rate, MNAD]\n",
    "\n",
    "# Save Voting/Median result\n",
    "# print(\"saving Voting/Median result...\")\n",
    "# np.savetxt('result_vm.txt', result_vm, fmt='%1.4f', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rilvP3pqmA81"
   },
   "outputs": [],
   "source": [
    "weather[:, 0]=weather[:, 0].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "la8rA7Sg_cfd",
    "outputId": "f75d9e02-f6e8-47f8-e046-d7b3789bcf15"
   },
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "id": "x6-nv8oX9IvQ",
    "outputId": "3f32646b-6419-4c8e-894d-0931df7f9809"
   },
   "outputs": [],
   "source": [
    "weather[:, 0].astype(np.float)\n",
    "nums_str_np = np.asarray(weather[:, 0])\n",
    "nums_int_np = nums_str_np.astype('int')\n",
    "nums_int_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4YzAFC38W1k",
    "outputId": "34dc6269-0479-44bd-e57c-179ae5d0dcfd"
   },
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 4, 7, 0],[0,0,0,0,0]])\n",
    "\n",
    "np.diff(x[:,0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
